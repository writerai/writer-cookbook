{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat History with Langchain\n",
    "\n",
    "This example will demonstrate how to create a basic chat bot using Langchain with a Writer LLM backend."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "Make sure you have a virtual environment selected if you don't want to install these globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --disable-pip-version-check\\\n",
    "    langchain python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Writer Langchain integration looks for two environment variables: `WRITER_ORG_ID` and `WRITER_API_KEY`. If you're running this notebook, make sure you have a `.env` file in this directory that looks like this:\n",
    "```\n",
    "WRITER_ORG_ID=<your org ID>\n",
    "WRITER_API_KEY=<your API key>\n",
    "```\n",
    "and run the following cell. You can alternatively use whatever method you want to set environment variables as long as they get set. \n",
    "\n",
    "Yet another alternative if you don't want environment variables is passing these parameters to the Langchain `Writer` object on construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import ConversationChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.llms import Writer\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversation chain\n",
    "\n",
    "First we need to create our chain. For this example we'll have a pretty standard `ConversationChain` with a Writer llm, and set verbose mode just so we can see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm = Writer(max_tokens=500, temperature=0),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"choices\":[{\"text\":\" Hi there! It\\'s nice to meet you. How can I help you today?\",\"logprobs\":null}]}'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.clear()\n",
    "conversation.predict(input=\"Hello!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it works! Kind of. But it also includes all the extra information that came with the API response. We don't want any of that for a chat bot, we just want the text. So we can create a simple parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WriterParser(BaseOutputParser[str]):\n",
    "    ignore_chain = True\n",
    "    ignore_llm = True\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        return json.loads(text)['choices'][0]['text']\n",
    "\n",
    "conversation.prompt.output_parser = WriterParser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test again with the `predict_and_parse` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.clear()\n",
    "conversation.predict_and_parse(input=\"Hello!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! But there's still a slight problem. What if we actually try to take advantage of the history now and ask multiple questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello!\n",
      "AI: {\"choices\":[{\"text\":\" Hi there! It's nice to meet you. How can I help you today?\",\"logprobs\":null}]}\n",
      "Human: Tell me about yourself\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' {\"choices\":[{\"text\":\"Sure! I\\'m an AI created to help people with their everyday tasks. I\\'m programmed to understand natural language and provide helpful information. I\\'m also constantly learning and growing, so I\\'m always up for a challenge! What else would you like to know?\",\"logprobs\":null}]}'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.clear()\n",
    "conversation.predict_and_parse(input=\"Hello!\")\n",
    "conversation.predict_and_parse(input=\"Tell me about yourself\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra data still gets put back into the message history. The AI sees this, and thinks it should add the extra characters to the beginning and end of its response. Not only does it make the responses less readable, but it will continue to add more and more copies making each back-and-forth add extra garbage. This is obviously no good, so how do we fix it? One way is to manually keep track of the message history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_message(message):\n",
    "    manual_memory = copy.deepcopy(conversation.memory.chat_memory)\n",
    "    response = conversation.predict_and_parse(input=message)\n",
    "    manual_memory.add_user_message(message)\n",
    "    manual_memory.add_ai_message(response)\n",
    "    conversation.memory.chat_memory = manual_memory\n",
    "    return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know this is pretty hacky, but it's the best I could do with the limitation that `ConversationChain` appends messages to history before they are run through the parser. I believe this is because parsers often return types that are not strings. I couldn't find a way to change this, or even disable automatic message appending, but perhaps that will change in the future. For now, at least overwriting the message history with a manual copy works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: How do I bake an apple pie?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: How do I bake an apple pie?\n",
      "AI:  Baking an apple pie is a great way to enjoy the flavors of fall! To make an apple pie, you'll need a 9-inch pie dish, a pastry blender, and the following ingredients: 4 cups of peeled and sliced apples, 1/2 cup of sugar, 1/4 teaspoon of salt, 1 teaspoon of ground cinnamon, 2 tablespoons of all-purpose flour, 2 tablespoons of butter, and a 9-inch unbaked pie crust. Preheat your oven to 425 degrees Fahrenheit. In a large bowl, combine the apples, sugar, salt, cinnamon, and flour. Place the mixture in the pie dish and dot with butter. Place the pie crust over the top of the dish and crimp the edges. Bake for 40-45 minutes, or until the crust is golden brown. Enjoy!\n",
      "Human: thanks!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: How do I bake an apple pie?\n",
      "AI:  Baking an apple pie is a great way to enjoy the flavors of fall! To make an apple pie, you'll need a 9-inch pie dish, a pastry blender, and the following ingredients: 4 cups of peeled and sliced apples, 1/2 cup of sugar, 1/4 teaspoon of salt, 1 teaspoon of ground cinnamon, 2 tablespoons of all-purpose flour, 2 tablespoons of butter, and a 9-inch unbaked pie crust. Preheat your oven to 425 degrees Fahrenheit. In a large bowl, combine the apples, sugar, salt, cinnamon, and flour. Place the mixture in the pie dish and dot with butter. Place the pie crust over the top of the dish and crimp the edges. Bake for 40-45 minutes, or until the crust is golden brown. Enjoy!\n",
      "Human: thanks!\n",
      "AI:  You're welcome! Is there anything else I can help you with?\n",
      "Human: what about a cherry one instead?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Sure! To make a cherry pie, you'll need a 9-inch pie dish, a pastry blender, and the following ingredients: 4 cups of pitted and halved cherries, 1/2 cup of sugar, 1/4 teaspoon of salt, 1 teaspoon of ground cinnamon, 2 tablespoons of all-purpose flour, 2 tablespoons of butter, and a 9-inch unbaked pie crust. Preheat your oven to 425 degrees Fahrenheit. In a large bowl, combine the cherries, sugar, salt, cinnamon, and flour. Place the mixture in the pie dish and dot with butter. Place the pie crust over the top of the dish and crimp the edges. Bake for 40-45 minutes, or until the crust is golden brown. Enjoy!\""
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.clear()\n",
    "\n",
    "chat_message(\"Hello!\")\n",
    "chat_message(\"How do I bake an apple pie?\")\n",
    "chat_message(\"thanks!\")\n",
    "chat_message(\"what about a cherry one instead?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for this example. To see more detail about managing memory with LLMs, take a look at the [Langchain memory documentation](https://python.langchain.com/en/latest/modules/memory.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
